{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMj0FvmNnyRerbhvJTtRRqL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ddhackiisc/code/blob/master/DILI/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1W_RZYGrnuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from input_data import DataSet\n",
        "from ugrnn import UGRNN\n",
        "from utils import model_params\n",
        "np.set_printoptions(threshold=np.inf, precision=4)\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "FLAGS = None\n",
        "\n",
        "\n",
        "def main(*args):\n",
        "    model_dir = os.path.join(FLAGS.output_dir, FLAGS.model_name)\n",
        "\n",
        "    if tf.gfile.Exists(model_dir):\n",
        "        tf.gfile.DeleteRecursively(model_dir)\n",
        "    tf.gfile.MakeDirs(model_dir)\n",
        "\n",
        "    with tf.Graph().as_default():\n",
        "        # Create a session for running Ops on the Graph.\n",
        "        sess = tf.Session()\n",
        "\n",
        "        logp_col_name = FLAGS.logp_col if FLAGS.add_logp else None\n",
        "\n",
        "        logger.info('Loading Training dataset from {:}'.format(FLAGS.training_file))\n",
        "        train_dataset = DataSet(csv_file_path=FLAGS.training_file, smile_col_name=FLAGS.smile_col,\n",
        "                                target_col_name=FLAGS.target_col, logp_col_name=logp_col_name,\n",
        "                                contract_rings=FLAGS.contract_rings)\n",
        "\n",
        "        logger.info('Loading validation dataset from {:}'.format(FLAGS.validation_file))\n",
        "        validation_dataset = DataSet(csv_file_path=FLAGS.validation_file, smile_col_name=FLAGS.smile_col,\n",
        "                                     target_col_name=FLAGS.target_col, logp_col_name=logp_col_name,\n",
        "                                     contract_rings=FLAGS.contract_rings)\n",
        "\n",
        "        logger.info(\"Creating Graph.\")\n",
        "\n",
        "\n",
        "        ugrnn_model = UGRNN(FLAGS.model_name, encoding_nn_hidden_size=FLAGS.model_params[0],\n",
        "                            encoding_nn_output_size=FLAGS.model_params[1], output_nn_hidden_size=FLAGS.model_params[2],\n",
        "                            batch_size=FLAGS.batch_size, learning_rate=0.001, add_logp=FLAGS.add_logp, \n",
        "                            clip_gradients=FLAGS.clip_gradient)\n",
        "\n",
        "\n",
        "\n",
        "        logger.info(\"Succesfully created graph.\")\n",
        "\n",
        "        init = tf.global_variables_initializer()\n",
        "        sess.run(init)\n",
        "        logger.info('Run the Op to initialize the variables')\n",
        "        ugrnn_model.train(sess, FLAGS.max_epochs, train_dataset, validation_dataset, model_dir)\n",
        "        ugrnn_model.save_model(sess, model_dir, FLAGS.max_epochs)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        "    logging.basicConfig(level=logging.INFO, format=log_format)\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument('--model_name', type=str, default='default_model',\n",
        "                        help='Name of the model')\n",
        "\n",
        "    parser.add_argument('--max_epochs', type=int, default=200,\n",
        "                        help='Number of epochs to run trainer.')\n",
        "\n",
        "    parser.add_argument('--batch_size', type=int, default=10,\n",
        "                        help='Batch size.')\n",
        "\n",
        "    parser.add_argument('--model_params', help=\"Model Parameters\", dest=\"model_params\", type=model_params, default = '7,7,5')\n",
        "\n",
        "    parser.add_argument('--learning_rate', type=float, default=0.001,\n",
        "                        help='Initial learning rate')\n",
        "\n",
        "    parser.add_argument('--output_dir', type=str, default='train',\n",
        "                        help='Directory for storing the trained models')\n",
        "\n",
        "    parser.add_argument('--training_file', type=str, default='data/delaney/train_delaney.csv',\n",
        "                        help='Path to the csv file containing training data set')\n",
        "\n",
        "    parser.add_argument('--validation_file', type=str, default='data/delaney/validate_delaney.csv',\n",
        "                        help='Path to the csv file containing validation data set')\n",
        "\n",
        "    parser.add_argument('--smile_col', type=str, default='smiles')\n",
        "\n",
        "    parser.add_argument('--logp_col', type=str, default='logp')\n",
        "\n",
        "    parser.add_argument('--target_col', type=str, default='solubility')\n",
        "\n",
        "    parser.add_argument('--contract_rings', dest='contract_rings',default = False)\n",
        "\n",
        "    parser.add_argument('--add_logp', dest='add_logp', default = False)\n",
        "    \n",
        "    parser.add_argument('--clip_gradient', dest='clip_gradient', default=False)\n",
        "    \n",
        "        \n",
        "    \n",
        "    \n",
        "\n",
        "    FLAGS = parser.parse_args()\n",
        "    \n",
        "    main()\n",
        "    #tf.app.run(main=main)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}