{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet_Adwaith.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ddhackiisc/code/blob/master/DILI/DILI_predict_ResNet/Resnet_Adwaith.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88WwyJK5lsK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import AveragePooling1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.convolutional import ZeroPadding1D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input \n",
        "from keras.models import Model\n",
        "from keras.layers import add\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKuAUGempDQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Resnet:\n",
        "  @staticmethod\n",
        "  def residual_module(data, K ,stride, chanDim=-1, red=False, reg=0.0001, bnEps=2e-5, bnMom=0.9, i=-1, j=-1):\n",
        "    shortcut = data #the shortcut branch of a residual module is initialized as the input\n",
        " \n",
        "    #First block of resudual module\n",
        "    bn1 = BatchNormalization(epsilon=bnEps, momentum=bnMom, name='bn1_'+str(i)+'_'+str(j))(data)\n",
        "    act1 = Activation(\"relu\",name='act1_'+str(i)+'_'+str(j))(bn1)\n",
        "    conv1 = Conv1D(K, 9, use_bias= False, kernel_regularizer=l2(reg), padding='same', name='conv1_'+str(i)+'_'+str(j))(act1)\n",
        " \n",
        "    #2nd block of residual module\n",
        "    bn2 = BatchNormalization(epsilon=bnEps, momentum=bnMom, name='bn2_'+str(i)+'_'+str(j))(conv1)\n",
        "    act2 = Activation(\"relu\", name='act2_'+str(i)+'_'+str(j))(bn2)\n",
        "    conv2 = Conv1D(K, 9, use_bias= False, kernel_regularizer=l2(reg),padding='same', name='conv2_'+str(i)+'_'+str(j))(act2)\n",
        " \n",
        "    #In the beginning of each stage of the resnet you will have adjust the shortcut dimensions\n",
        "    if red:\n",
        "      shortcut = Conv1D(K, 9, use_bias=False, kernel_regularizer=l2(reg), padding='same', name='conv_srt_'+str(i)+'_'+str(j))(act1)\n",
        " \n",
        "    x = add([conv2, shortcut], name='add_'+str(i)+'_'+str(j)) #add the second residual moduleand the shortcut\n",
        " \n",
        "    return x\n",
        " \n",
        "  @staticmethod\n",
        "  def build(input_shape, classes, stages, filters, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
        "    #create input and apply BN\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = BatchNormalization(epsilon=bnEps, momentum=bnMom, name='bn_input')(inputs)\n",
        " \n",
        "    #Create the starting conv layer\n",
        "    x = Conv1D(filters[0], 9, use_bias=False, padding='same', kernel_regularizer=l2(reg), name='conv_first_layer')(x)\n",
        "    x = BatchNormalization(epsilon=bnEps, momentum=bnMom, name='bn_first_layer')(x)\n",
        "    x = Activation('relu', name='act_first_layer')(x)\n",
        "    \n",
        " \n",
        "    #loop over the stages\n",
        "    for i in range(0, len(stages)):\n",
        "      stride  = 1\n",
        "      #first layer in each stage should reduce the dimensions of input \n",
        "      x = Resnet.residual_module(x, filters[i+1], stride, red=True, bnEps=bnEps, bnMom=bnMom, i=i+1, j=1)\n",
        " \n",
        "      for j in range(0, stages[i] -1):\n",
        "        #apply a renset module\n",
        "        x = Resnet.residual_module(x, filters[i+1], stride, bnEps=bnEps, bnMom=bnMom, i=i+1, j=j+2)\n",
        "    \n",
        "    x = BatchNormalization(epsilon=bnEps, momentum=bnMom, name='bn_last_layer')(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        " \n",
        "    #Final dense layer applied with softmax activation\n",
        "    x = Dense(970, kernel_regularizer=l2(reg), name='out_dense_layer')(x)\n",
        "    x = Dense(classes, activation='sigmoid', name='last_layer', kernel_regularizer=l2(reg))(x)\n",
        "    #x = Activation('softmax')(x)\n",
        "    # x = Activation('sigmoid', name='out_act')(x)\n",
        " \n",
        " \n",
        "    #create the model\n",
        "    model = Model(inputs, x, name='resnet')\n",
        " \n",
        "    #return the model\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WxKACDLCARw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stages = []\n",
        "filters = [9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSNntl5YBd8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_model = Resnet.build((881,1), 1, stages, filters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab8laLKjdui2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPEvHggyenOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam \n",
        "\n",
        "\n",
        "# my_model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'] )\n",
        "my_model.compile(optimizer=Adam(learning_rate=0.0001), loss=tf.keras.losses.MeanSquaredError(), metrics=['accuracy'] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_GGUmuXeVq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard\n",
        " \n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "!rm -rf ./logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ps25NmgPpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(\"combined_train.csv\")\n",
        "train_smiles = train_df['smiles'].to_numpy()\n",
        "train_labels = train_df['label'].to_numpy()\n",
        " \n",
        "test_df = pd.read_csv(\"combined_test.csv\")\n",
        "test_smiles = test_df[\"smiles\"].to_numpy()\n",
        "test_labels = test_df[\"label\"].to_numpy()\n",
        " \n",
        " \n",
        "train_input = pd.read_csv('train_input.csv', header = None).to_numpy()\n",
        "test_input = pd.read_csv('test_input.csv', header = None).to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prvwhRo8hVaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "bbfc85b1-495c-43fc-a31e-b7232fb581b2"
      },
      "source": [
        "# # Define the Keras TensorBoard callback.\n",
        "# logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "\n",
        "# my_model.fit(train_input, train_labels, epochs=10, verbose=2, validation_split=0.1, batch_size=32, callbacks=[tensorboard_callback])\n",
        "\n",
        "my_model.fit(train_input, train_labels, epochs=10, verbose=2, validation_split=0.1, batch_size=47)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "9/9 - 0s - loss: 0.2495 - accuracy: 0.5394 - val_loss: 0.2499 - val_accuracy: 0.5709\n",
            "Epoch 2/10\n",
            "9/9 - 0s - loss: 0.2496 - accuracy: 0.5373 - val_loss: 0.2500 - val_accuracy: 0.5673\n",
            "Epoch 3/10\n",
            "9/9 - 0s - loss: 0.2497 - accuracy: 0.5371 - val_loss: 0.2500 - val_accuracy: 0.5710\n",
            "Epoch 4/10\n",
            "9/9 - 0s - loss: 0.2495 - accuracy: 0.5375 - val_loss: 0.2497 - val_accuracy: 0.5746\n",
            "Epoch 5/10\n",
            "9/9 - 0s - loss: 0.2499 - accuracy: 0.5360 - val_loss: 0.2503 - val_accuracy: 0.5670\n",
            "Epoch 6/10\n",
            "9/9 - 0s - loss: 0.2497 - accuracy: 0.5369 - val_loss: 0.2501 - val_accuracy: 0.5670\n",
            "Epoch 7/10\n",
            "9/9 - 0s - loss: 0.2497 - accuracy: 0.5358 - val_loss: 0.2495 - val_accuracy: 0.5746\n",
            "Epoch 8/10\n",
            "9/9 - 0s - loss: 0.2497 - accuracy: 0.5382 - val_loss: 0.2493 - val_accuracy: 0.5773\n",
            "Epoch 9/10\n",
            "9/9 - 0s - loss: 0.2496 - accuracy: 0.5374 - val_loss: 0.2501 - val_accuracy: 0.5671\n",
            "Epoch 10/10\n",
            "9/9 - 0s - loss: 0.2497 - accuracy: 0.5366 - val_loss: 0.2499 - val_accuracy: 0.5670\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f39600d4588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grM0jsWrjSCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXEFF3q_kLAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "063df38c-f55b-4d3f-d72e-a118a032bf52"
      },
      "source": [
        "test_scores = my_model.evaluate(test_input, test_labels, verbose=2)\n",
        "print(\"Test loss:\", test_scores[0])\n",
        "print(\"Test accuracy:\", test_scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 - 0s - loss: 0.2588 - accuracy: 0.4433\n",
            "Test loss: 0.258788138628006\n",
            "Test accuracy: 0.443303644657135\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}